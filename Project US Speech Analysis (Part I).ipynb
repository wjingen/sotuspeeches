{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This data science project focuses on Natural Language Processing, together with POS Tagging. In this project, we analyse State of the Union speeches, which are speeches given by the current US President every year.\n",
    "\n",
    "We analyse President Barack Obama's speeches from 2010 to 2016 , and President Donald Trump's speeches from 2018 to 2020."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparatory Work\n",
    "\n",
    "Obtain full speeches from Obama and Trump's State of the Union Speeches.\n",
    "\n",
    "https://obamawhitehouse.archives.gov/sotu/\n",
    "\n",
    "https://trumpwhitehouse.archives.gov/sotu/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Data Collection & Cleaning\n",
    "\n",
    "We import the speeches and perform data cleaning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "obama2010 = \"\"\n",
    "with open(\"speeches/obama2010.txt\", 'r') as f:\n",
    "    for line in f:\n",
    "        obama2010 += line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['speeches\\\\obama2010.txt', 'speeches\\\\obama2011.txt', 'speeches\\\\obama2012.txt', 'speeches\\\\obama2013.txt', 'speeches\\\\obama2014.txt', 'speeches\\\\obama2015.txt', 'speeches\\\\obama2016.txt', 'speeches\\\\trump2018.txt', 'speeches\\\\trump2019.txt', 'speeches\\\\trump2020.txt']\n"
     ]
    }
   ],
   "source": [
    "list_of_speeches = []\n",
    "for file in glob.glob(\"speeches/*.txt\"):\n",
    "    list_of_speeches.append(file)\n",
    "print(list_of_speeches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "speeches_text = []\n",
    "for speech in list_of_speeches:\n",
    "    new_speech = \"\"\n",
    "    with open(str(speech), 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            new_speech += line\n",
    "    speeches_text.append(new_speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['obama', 'obama', 'obama', 'obama', 'obama', 'obama', 'obama', 'trump', 'trump', 'trump']\n"
     ]
    }
   ],
   "source": [
    "name = [speech[9:-8] for speech in list_of_speeches]\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = [i for i in range(2010,2021) if (i!=2017)]\n",
    "# print(year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating DataFrame\n",
    "dictionary = {\"filename\":list_of_speeches, \"name\":name, \"year\":year,\"speech\":speeches_text}\n",
    "df = pd.DataFrame(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to CSV\n",
    "df.to_csv(\"part1.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
